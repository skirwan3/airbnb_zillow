{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3485433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"Zillow_Airbnb.csv\")\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700cf15e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>City</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>Date</th>\n",
       "      <th>ZHVI</th>\n",
       "      <th>Listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>394355</td>\n",
       "      <td>29</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>167608.803584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>394355</td>\n",
       "      <td>29</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>168157.892276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>394355</td>\n",
       "      <td>29</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>168656.684383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>394355</td>\n",
       "      <td>29</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2000-04-30</td>\n",
       "      <td>169450.508196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>394355</td>\n",
       "      <td>29</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>2000-05-31</td>\n",
       "      <td>170048.593123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>4721</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>887956.929337</td>\n",
       "      <td>14349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>4722</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>884296.450518</td>\n",
       "      <td>13785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>4723</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>880012.047421</td>\n",
       "      <td>13042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>4724</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>871774.871645</td>\n",
       "      <td>11029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>4725</td>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>861761.432293</td>\n",
       "      <td>3714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  RegionID  SizeRank             City RegionType StateName  \\\n",
       "0              0    394355        29       Austin, TX        msa        TX   \n",
       "1              1    394355        29       Austin, TX        msa        TX   \n",
       "2              2    394355        29       Austin, TX        msa        TX   \n",
       "3              3    394355        29       Austin, TX        msa        TX   \n",
       "4              4    394355        29       Austin, TX        msa        TX   \n",
       "...          ...       ...       ...              ...        ...       ...   \n",
       "4721        4721    753899         2  Los Angeles, CA        msa        CA   \n",
       "4722        4722    753899         2  Los Angeles, CA        msa        CA   \n",
       "4723        4723    753899         2  Los Angeles, CA        msa        CA   \n",
       "4724        4724    753899         2  Los Angeles, CA        msa        CA   \n",
       "4725        4725    753899         2  Los Angeles, CA        msa        CA   \n",
       "\n",
       "            Date           ZHVI  Listings  \n",
       "0     2000-01-31  167608.803584         0  \n",
       "1     2000-02-29  168157.892276         0  \n",
       "2     2000-03-31  168656.684383         0  \n",
       "3     2000-04-30  169450.508196         0  \n",
       "4     2000-05-31  170048.593123         0  \n",
       "...          ...            ...       ...  \n",
       "4721  2022-10-31  887956.929337     14349  \n",
       "4722  2022-11-30  884296.450518     13785  \n",
       "4723  2022-12-31  880012.047421     13042  \n",
       "4724  2023-01-31  871774.871645     11029  \n",
       "4725  2023-02-28  861761.432293      3714  \n",
       "\n",
       "[4726 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83170f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat groupby object grouped by city\n",
    "grouped = data.groupby(data['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1aee3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data into dictionary with city as keys\n",
    "groupdict = {}\n",
    "for val in set(data['City'].values):\n",
    "    groupdict[val] = grouped.get_group(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49497b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of first nonzero dates for listings; that is, date of first Airbnb listing\n",
    "list = []\n",
    "for key in set(groupdict.keys()):\n",
    "    list.append(groupdict[key].iloc[groupdict[key]['Listings'].to_numpy().nonzero()[0]].iloc[0]['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23fd401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n",
      "/var/folders/60/bzl3rvnx2js1r_pvl2bzbtrw0000gn/T/ipykernel_53130/60717528.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "# Convert date values to datetime type (currently strings)\n",
    "for key in set(groupdict.keys()):\n",
    "    groupdict[key]['Date'] = pd.to_datetime(groupdict[key]['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840c7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among all cities, the latest date of first listing is October 2011; as a result, for simplicity sake, we'll start with Dec 31, 2011, equivalent to the start of 2012.\n",
    "for key in set(groupdict.keys()):\n",
    "    groupdict[key] = groupdict[key][groupdict[key]['Date'] >= '2011-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bccef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns not to be included in models\n",
    "for key in set(groupdict.keys()):\n",
    "    groupdict[key] = groupdict[key].drop(columns = ['Unnamed: 0', 'RegionID', 'SizeRank', 'City', 'RegionType', 'StateName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff82ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in secondary features (federal funds rate, CPI, unemployment rate)\n",
    "rate = pd.read_csv(\"FEDFUNDS.csv\")\n",
    "cpi = pd.read_csv(\"CPIAUCSL.csv\")\n",
    "unrate = pd.read_csv(\"UNRATE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aed91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime type\n",
    "rate['DATE'] = pd.to_datetime(rate['DATE'], format='%m/%d/%y')\n",
    "cpi['DATE'] = pd.to_datetime(cpi['DATE'], format='%m/%d/%y')\n",
    "unrate['DATE'] = pd.to_datetime(unrate['DATE'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ed6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join new values into dictionary of dataframes\n",
    "for key in set(groupdict.keys()):\n",
    "    groupdict[key] = groupdict[key].merge(rate, left_on = 'Date', right_on = 'DATE')\n",
    "    groupdict[key] = groupdict[key].drop(columns = ['DATE', 'DATE'])\n",
    "    groupdict[key] = groupdict[key].merge(cpi, left_on = 'Date', right_on = 'DATE')\n",
    "    groupdict[key] = groupdict[key].drop(columns = ['DATE'])\n",
    "    groupdict[key] = groupdict[key].merge(unrate, left_on = 'Date', right_on = 'DATE')\n",
    "    groupdict[key] = groupdict[key].drop(columns = ['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8fc637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to use for first difference model\n",
    "diffdict = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    diffdict[key] = groupdict[key].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d603b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values to difference between months for diffdict, remove first row (NaN value)\n",
    "for key in set(diffdict.keys()):\n",
    "    diffdict[key]['ZHVI'] = diffdict[key]['ZHVI'].diff()\n",
    "    diffdict[key]['Listings'] = diffdict[key]['Listings'].diff()\n",
    "    diffdict[key]['FEDFUNDS'] = diffdict[key]['FEDFUNDS'].diff()\n",
    "    diffdict[key]['CPIAUCSL'] = diffdict[key]['CPIAUCSL'].diff()\n",
    "    diffdict[key]['UNRATE'] = diffdict[key]['UNRATE'].diff()\n",
    "    diffdict[key] = diffdict[key][diffdict[key]['Date'] > '2011-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7d32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x's and y's for MLR model\n",
    "reg_xs = {}\n",
    "reg_ys = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    reg_xs[key] = groupdict[key].drop(columns = ['Date', 'ZHVI'])\n",
    "    reg_ys[key] = groupdict[key]['ZHVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "780890e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x's and y's for first difference model\n",
    "diff_xs = {}\n",
    "diff_ys = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    diff_xs[key] = diffdict[key].drop(columns = ['Date', 'ZHVI'])\n",
    "    diff_ys[key] = diffdict[key]['ZHVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1efc2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining vif function\n",
    "def vif(data):\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"predictors\"] = data.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "\n",
    "    return(vif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb1ada82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MLR model; get p-values, R^2 values, and summary ourputs\n",
    "import statsmodels.api as sm\n",
    "reg_models = {}\n",
    "p_values_reg = {}\n",
    "R_sq_reg = {}\n",
    "summaries_reg = {}\n",
    "vif_reg = {}\n",
    "\n",
    "for key in set(groupdict.keys()):\n",
    "    \n",
    "    reg_models[key] = sm.OLS(reg_ys[key],reg_xs[key])\n",
    "    \n",
    "    fii = reg_models[key].fit()\n",
    "    \n",
    "    p_values_reg[key] = fii.summary2().tables[1]['P>|t|']\n",
    "    \n",
    "    R_sq_reg[key] = fii.summary2().tables[0][1][6]\n",
    "    \n",
    "    summaries_reg[key] = fii.summary()\n",
    "    \n",
    "    vif_reg[key] = calc_vif(reg_xs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "925fdfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austin, TX': 'No',\n",
       " 'Boston, MA': 'No',\n",
       " 'Chicago, IL': 'No',\n",
       " 'Dallas, TX': 'No',\n",
       " 'New York, NY': 'No',\n",
       " 'Portland, OR': 'No',\n",
       " 'Salem, OR': 'No',\n",
       " 'Los Angeles, CA': 'No',\n",
       " 'San Diego, CA': 'No',\n",
       " 'Minneapolis, MN': 'No',\n",
       " 'Nashville, TN': 'No',\n",
       " 'Denver, CO': 'No',\n",
       " 'Columbus, OH': 'No',\n",
       " 'Washington, DC': 'No',\n",
       " 'Seattle, WA': 'No',\n",
       " 'New Orleans, LA': 'No',\n",
       " 'San Francisco, CA': 'No'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Multicolinearity using VIF in MLR model\n",
    "\n",
    "# See if VIF for each IV is >= max(10,(1/(1-R_sq)))\n",
    "MC_Issues_Reg = {}\n",
    "\n",
    "for key in set(groupdict.keys()):\n",
    "    vif_df = vif_reg[key]\n",
    "    vif_df['vif_threshold'] = (1/(1-float(R_sq_reg[key])))\n",
    "    vif_df['mc_issue'] = vif_df.apply(lambda row: 1 if row['VIF'] >= max(10,row['vif_threshold']) else 0, axis=1)\n",
    "    if sum(vif_df['mc_issue']) > 0:\n",
    "        MC_Issues_Reg[key] = 'Yes'\n",
    "    else:\n",
    "        MC_Issues_Reg[key] = 'No'\n",
    "        \n",
    "MC_Issues_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3e94121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run first difference model; get p-values, R^2 values, and summary ourputs\n",
    "import statsmodels.api as sm\n",
    "diff_models = {}\n",
    "p_values_diff = {}\n",
    "R_sq_diff = {}\n",
    "summaries_diff = {}\n",
    "vif_diff = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    diff_models[key] = sm.OLS(diff_ys[key],diff_xs[key])\n",
    "    fii = diff_models[key].fit()\n",
    "    p_values_diff[key] = fii.summary2().tables[1]['P>|t|']\n",
    "    R_sq_diff[key] = fii.summary2().tables[0][1][6]\n",
    "    summaries_diff[key] = fii.summary()\n",
    "    vif_diff[key] = calc_vif(diff_xs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f8501fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austin, TX': 'No',\n",
       " 'Boston, MA': 'No',\n",
       " 'Chicago, IL': 'No',\n",
       " 'Dallas, TX': 'No',\n",
       " 'New York, NY': 'No',\n",
       " 'Portland, OR': 'No',\n",
       " 'Salem, OR': 'No',\n",
       " 'Los Angeles, CA': 'No',\n",
       " 'San Diego, CA': 'No',\n",
       " 'Minneapolis, MN': 'No',\n",
       " 'Nashville, TN': 'No',\n",
       " 'Denver, CO': 'No',\n",
       " 'Columbus, OH': 'No',\n",
       " 'Washington, DC': 'No',\n",
       " 'Seattle, WA': 'No',\n",
       " 'New Orleans, LA': 'No',\n",
       " 'San Francisco, CA': 'No'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Multicolinearity using VIF in first difference model\n",
    "\n",
    "# See if VIF for each IV is >= max(10,(1/(1-R_sq)))\n",
    "MC_Issues_diff = {}\n",
    "\n",
    "for key in set(groupdict.keys()):\n",
    "    vif_df = vif_diff[key]\n",
    "    vif_df['vif_threshold'] = (1/(1-float(R_sq_diff[key])))\n",
    "    vif_df['mc_issue'] = vif_df.apply(lambda row: 1 if row['VIF'] >= max(10,row['vif_threshold']) else 0, axis=1)\n",
    "    if sum(vif_df['mc_issue']) > 0:\n",
    "        MC_Issues_diff[key] = 'Yes'\n",
    "    else:\n",
    "        MC_Issues_diff[key] = 'No'\n",
    "        \n",
    "MC_Issues_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d115cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients aren't highly interpretable for determining variable impact beyond p-values; normalize variables to allow for interpretability\n",
    "scaled_reg_xs = {}\n",
    "scaled_reg_ys = {}\n",
    "scaled_diff_xs = {}\n",
    "scaled_diff_ys = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    scaled_reg_xs[key] = (reg_xs[key]-reg_xs[key].mean())/reg_xs[key].std()\n",
    "    scaled_reg_ys[key] = (reg_ys[key]-reg_ys[key].mean())/reg_ys[key].std()\n",
    "    scaled_diff_xs[key] = (diff_xs[key]-diff_xs[key].mean())/diff_xs[key].std()\n",
    "    scaled_diff_ys[key] = (diff_ys[key]-diff_ys[key].mean())/diff_ys[key].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9eb7c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MLR model on scaled data; get p-values, R^2 values, and summary ourputs\n",
    "reg_models_scaled = {}\n",
    "p_values_reg_scaled = {}\n",
    "R_sq_reg_scaled = {}\n",
    "summaries_reg_scaled = {}\n",
    "vif_reg_scaled = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    reg_models_scaled[key] = sm.OLS(scaled_reg_ys[key],scaled_reg_xs[key])\n",
    "    fii = reg_models_scaled[key].fit()\n",
    "    p_values_reg_scaled[key] = fii.summary2().tables[1]['P>|t|']\n",
    "    R_sq_reg_scaled[key] = fii.summary2().tables[0][1][6]\n",
    "    summaries_reg_scaled[key] = fii.summary()\n",
    "    vif_reg_scaled[key] = calc_vif(scaled_reg_xs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca9e24c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austin, TX': 'No',\n",
       " 'Boston, MA': 'No',\n",
       " 'Chicago, IL': 'No',\n",
       " 'Dallas, TX': 'No',\n",
       " 'New York, NY': 'No',\n",
       " 'Portland, OR': 'No',\n",
       " 'Salem, OR': 'No',\n",
       " 'Los Angeles, CA': 'No',\n",
       " 'San Diego, CA': 'No',\n",
       " 'Minneapolis, MN': 'No',\n",
       " 'Nashville, TN': 'No',\n",
       " 'Denver, CO': 'No',\n",
       " 'Columbus, OH': 'No',\n",
       " 'Washington, DC': 'No',\n",
       " 'Seattle, WA': 'No',\n",
       " 'New Orleans, LA': 'No',\n",
       " 'San Francisco, CA': 'No'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Multicolinearity using VIF in MLR model\n",
    "\n",
    "# See if VIF for each IV is >= max(10,(1/(1-R_sq)))\n",
    "MC_Issues_Reg_Scaled = {}\n",
    "\n",
    "for key in set(groupdict.keys()):\n",
    "    vif_df = vif_reg_scaled[key]\n",
    "    vif_df['vif_threshold'] = (1/(1-float(R_sq_reg_scaled[key])))\n",
    "    vif_df['mc_issue'] = vif_df.apply(lambda row: 1 if row['VIF'] >= max(10,row['vif_threshold']) else 0, axis=1)\n",
    "    if sum(vif_df['mc_issue']) > 0:\n",
    "        MC_Issues_Reg_Scaled[key] = 'Yes'\n",
    "    else:\n",
    "        MC_Issues_Reg_Scaled[key] = 'No'\n",
    "        \n",
    "MC_Issues_Reg_Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c412b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run first difference model on scaled data; get p-values, R^2 values, and summary ourputs\n",
    "diff_models_scaled = {}\n",
    "p_values_diff_scaled = {}\n",
    "R_sq_diff_scaled = {}\n",
    "summaries_diff_scaled = {}\n",
    "vif_diff_scaled = {}\n",
    "for key in set(groupdict.keys()):\n",
    "    diff_models_scaled[key] = sm.OLS(scaled_diff_ys[key],scaled_diff_xs[key])\n",
    "    fii = diff_models_scaled[key].fit()\n",
    "    p_values_diff_scaled[key] = fii.summary2().tables[1]['P>|t|']\n",
    "    R_sq_diff_scaled[key] = fii.summary2().tables[0][1][6]\n",
    "    summaries_diff_scaled[key] = fii.summary()\n",
    "    vif_diff_scaled[key] = calc_vif(scaled_diff_xs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78e761c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austin, TX': 'No',\n",
       " 'Boston, MA': 'No',\n",
       " 'Chicago, IL': 'No',\n",
       " 'Dallas, TX': 'No',\n",
       " 'New York, NY': 'No',\n",
       " 'Portland, OR': 'No',\n",
       " 'Salem, OR': 'No',\n",
       " 'Los Angeles, CA': 'No',\n",
       " 'San Diego, CA': 'No',\n",
       " 'Minneapolis, MN': 'No',\n",
       " 'Nashville, TN': 'No',\n",
       " 'Denver, CO': 'No',\n",
       " 'Columbus, OH': 'No',\n",
       " 'Washington, DC': 'No',\n",
       " 'Seattle, WA': 'No',\n",
       " 'New Orleans, LA': 'No',\n",
       " 'San Francisco, CA': 'No'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Multicolinearity using VIF in first difference model\n",
    "\n",
    "# See if VIF for each IV is >= max(10,(1/(1-R_sq)))\n",
    "MC_Issues_diff_scaled = {}\n",
    "\n",
    "for key in set(groupdict.keys()):\n",
    "    vif_df = vif_diff_scaled[key]\n",
    "    vif_df['vif_threshold'] = (1/(1-float(R_sq_diff_scaled[key])))\n",
    "    vif_df['mc_issue'] = vif_df.apply(lambda row: 1 if row['VIF'] >= max(10,row['vif_threshold']) else 0, axis=1)\n",
    "    if sum(vif_df['mc_issue']) > 0:\n",
    "        MC_Issues_diff_scaled[key] = 'Yes'\n",
    "    else:\n",
    "        MC_Issues_diff_scaled[key] = 'No'\n",
    "        \n",
    "MC_Issues_diff_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec0642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
